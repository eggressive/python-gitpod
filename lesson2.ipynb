{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Engineering with Llama 2\n",
    "Getting started with Llama 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import llama helper function\n",
    "from modules.utils import llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the prompt\n",
    "prompt = \"Help me propose to our customers to replace Databricks services with Amazon EMR.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sure, here's a sample proposal that you can use to propose replacing Databricks services with Amazon EMR:\n",
      "\n",
      "Subject: Enhancing Your Data Engineering Capabilities with Amazon EMR\n",
      "\n",
      "Dear [Customer Name],\n",
      "\n",
      "I hope this message finds you well. As your trusted technology partner, we are committed to providing you with the best possible solutions to meet your data engineering needs. With the increasing demand for big data processing and analytics, we believe that Amazon EMR can offer significant benefits to your organization.\n",
      "\n",
      "Why Amazon EMR?\n",
      "\n",
      "Amazon EMR is a fully managed big data processing service that makes it easy to analyze all your data using Spark, Hive, Hadoop, and other popular data processing frameworks. Here are some key benefits of using Amazon EMR:\n",
      "\n",
      "1. Scalability: Amazon EMR can handle large volumes of data and scale up or down as needed, making it easy to handle spikes in data processing requirements.\n",
      "2. Security: Amazon EMR provides robust security features, including encryption at rest and in transit, to ensure that your data is secure.\n",
      "3. Cost-effective: Amazon EMR offers a cost-effective solution for data processing, as you only pay for the resources you use.\n",
      "4. Ease of use: Amazon EMR provides a simple and intuitive user interface, making it easy to manage and monitor your data processing tasks.\n",
      "\n",
      "Why replace Databricks with Amazon EMR?\n",
      "\n",
      "While Databricks is a popular data engineering platform, it may not offer the same level of scalability, security, and cost-effectiveness as Amazon EMR. Here are some reasons why we believe Amazon EMR is a better fit for your organization:\n",
      "\n",
      "1. Scalability: Amazon EMR can handle large volumes of data and scale up or down as needed, making it easy to handle spikes in data processing requirements. Databricks, on the other hand, may struggle with large datasets and may require additional infrastructure to handle scale.\n",
      "2. Security: Amazon EMR provides robust security features, including encryption at rest and in transit, to ensure that your data is secure. Databricks also provides security features, but they may not be as robust as Amazon EMR.\n",
      "3. Cost-effectiveness: Amazon EMR offers a cost-effective solution for data processing, as you only pay for the resources you use. Databricks, on the other hand, may require a fixed fee for its services, which may not be as cost-effective for organizations with variable data processing requirements.\n",
      "4. Integration: Amazon EMR can integrate with a wide range of data sources and sinks, including Amazon S3, Amazon Redshift, and Amazon DynamoDB. Databricks, on the other hand, may have limited integration options.\n",
      "\n",
      "Proposal:\n",
      "\n",
      "Based on the above reasons, we propose replacing Databricks with Amazon EMR for your data engineering needs. Here are the key steps involved in the transition:\n",
      "\n",
      "1. Assessment: We will conduct an assessment of your current data engineering infrastructure and identify areas where Amazon EMR can provide significant benefits.\n",
      "2. Migration: We will migrate your data processing tasks to Amazon EMR, ensuring that your data is secure and easily accessible.\n",
      "3. Training: We will provide training to your team on how to use Amazon EMR, including its user interface, security features, and data processing capabilities.\n",
      "4. Monitoring: We will monitor your Amazon EMR cluster to ensure that it is running smoothly and efficiently, and make any necessary adjustments to optimize performance.\n",
      "\n",
      "Conclusion:\n",
      "\n",
      "We believe that Amazon EMR is a superior data engineering platform to Databricks, offering better scalability, security, cost-effectiveness, and integration capabilities. By replacing Databricks with Amazon EMR, we can help you improve your data engineering capabilities, reduce costs, and enhance your overall data processing capabilities. We look forward to working with you to make this transition a success.\n",
      "\n",
      "Thank you for considering our proposal. Please let us know if you have any questions or concerns.\n",
      "\n",
      "Best regards,\n",
      "\n",
      "[Your Name]\n",
      "[Your Company]\n"
     ]
    }
   ],
   "source": [
    "# pass prompt to the llama function, store output as 'response' then print\n",
    "response = llama(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:\n",
      "[INST]Help me propose to our customers to replace Databricks services with Amazon EMR.[/INST]\n",
      "\n",
      "model: togethercomputer/alpaca-7b\n",
      "\n",
      "We are considering replacing our Databricks services with Amazon EMR. We have a few questions that we would like to ask our customers to help us make an informed decision.\n",
      "What advantages does Amazon EMR offer compared to Databricks?\n",
      "What are the main differences between the two services?\n",
      "What have been your experiences with Amazon EMR?\n",
      "We appreciate your input and thank you for your time.\n"
     ]
    }
   ],
   "source": [
    "# Set verbose to True to see the full prompt that is passed to the model.\n",
    "prompt = \"Help me propose to our customers to replace Databricks services with Amazon EMR.\"\n",
    "response = llama(prompt, model=\"togethercomputer/alpaca-7b\", verbose=True)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat vs. base models\n",
    "\n",
    "Ask model a simple question to demonstrate the different behavior of chat vs. base models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:\n",
      "[INST]What is the capital of France?[/INST]\n",
      "\n",
      "model: meta-llama/Llama-2-70b-chat-hf\n"
     ]
    }
   ],
   "source": [
    "### chat model\n",
    "prompt = \"What is the capital of France?\"\n",
    "response = llama(prompt, \n",
    "                 verbose=True,\n",
    "                 model=\"meta-llama/Llama-2-70b-chat-hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:\n",
      "What is the capital of France?\n",
      "\n",
      "model: meta-llama/Llama-2-7b-chat-hf\n"
     ]
    }
   ],
   "source": [
    "### base model\n",
    "prompt = \"What is the capital of France?\"\n",
    "response = llama(prompt, \n",
    "                 verbose=True,\n",
    "                 add_inst=False,\n",
    "                 model=\"meta-llama/Llama-2-7b-chat-hf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how the prompt does not include the [INST] and [/INST] tags as add_inst was set to `False`.\n",
    "\n",
    "It is because the base models do not understand the instruction tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Answer: The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing the temperature setting\n",
    "\n",
    "For consistent responses set the temperature to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:\n",
      "[INST]\n",
      "Help me propose to our customers to replace Databricks services with Amazon EMR.\n",
      "Here are details about our customers:\n",
      "They are developer teams developing applications for financial services.\n",
      "Our customers use mixed workloads ranging from ETL batch workloads to long-term Spark processing jobs.\n",
      "Our customers often use Hive for SQL processing.\n",
      "[/INST]\n",
      "\n",
      "model: togethercomputer/llama-2-7b-chat\n",
      "  Subject: Enhancing Your Data Processing Capabilities with Amazon EMR\n",
      "\n",
      "Dear [Customer Name],\n",
      "\n",
      "I hope this message finds you well. As your trusted partner in data processing, we are excited to share with you an opportunity to enhance your data processing capabilities with Amazon EMR. Our team has been closely evaluating your current data processing needs, and we believe that Amazon EMR can provide a more efficient, scalable, and cost-effective solution for your mixed workloads.\n",
      "\n",
      "Background:\n",
      "Databricks has been a valuable partner in providing data processing services to your developer teams. However, we have observed that your workloads are becoming increasingly complex, and Databricks may not be able to meet your growing needs. Amazon EMR is a fully managed service that provides a scalable, secure, and high-performance environment for big data processing. It supports a wide range of data processing tasks, including ETL batch workloads, long-term Spark processing jobs, and SQL processing with Hive.\n",
      "\n",
      "Benefits of Amazon EMR:\n",
      "\n",
      "1. Scalability: Amazon EMR can quickly scale up or down to meet your changing data processing needs, without requiring additional infrastructure or maintenance.\n",
      "2. Security: Amazon EMR provides a secure environment for data processing, with built-in security features such as encryption, access controls, and auditing.\n",
      "3. High-performance: Amazon EMR is designed to provide high-performance data processing, with support for popular data processing frameworks such as Spark, Hive, and Hadoop.\n",
      "4. Cost-effective: Amazon EMR offers a cost-effective solution for data processing, with no upfront costs, no capacity constraints, and a pay-as-you-go pricing model.\n",
      "\n",
      "Proposal:\n",
      "We propose replacing Databricks services with Amazon EMR for your data processing needs. This will enable your developer teams to leverage the scalability, security, and high-performance capabilities of Amazon EMR, while continuing to use the tools and frameworks they are familiar with.\n",
      "\n",
      "Transition Plan:\n",
      "\n",
      "1. Assessment: We will conduct a thorough assessment of your current data processing environment to identify any potential issues or areas for improvement.\n",
      "2. Migration: We will work with your team to migrate your data processing workloads to Amazon EMR, ensuring a seamless transition with minimal disruption to your operations.\n",
      "3. Training: We will provide training and support to help your team get the most out of Amazon EMR, including best practices for data processing, security, and performance optimization.\n",
      "4. Ongoing Support: We will provide ongoing support and maintenance to ensure that your data processing environment continues to meet your evolving needs.\n",
      "\n",
      "Conclusion:\n",
      "We believe that Amazon EMR can provide a more efficient, scalable, and cost-effective solution for your data processing needs. By replacing Databricks services with Amazon EMR, your developer teams can leverage a fully managed service that can handle your mixed workloads with ease. We are confident that this transition will enable your team to focus on delivering innovative financial services applications, while we handle the data processing needs.\n",
      "\n",
      "Please let us know if you have any questions or concerns, and we will be happy to discuss this proposal further.\n",
      "\n",
      "Best regards,\n",
      "\n",
      "[Your Name]\n",
      "[Your Company]\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Help me propose to our customers to replace Databricks services with Amazon EMR.\n",
    "Here are details about our customers:\n",
    "They are developer teams developing applications for financial services.\n",
    "Our customers use mixed workloads ranging from ETL batch workloads to long-term Spark processing jobs.\n",
    "Our customers often use Hive for SQL processing.\n",
    "\"\"\"\n",
    "response = llama(prompt, temperature=0.0, verbose=True)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': {'message': 'Request was rejected due to rate limiting. As a free user, your QPS is 1. If you want more, please upgrade your account.', 'type': 'credit_limit', 'param': None, 'code': None}}\n"
     ]
    }
   ],
   "source": [
    "# Run the code again - the output should be identical\n",
    "response = llama(prompt, temperature=0.0)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Title: Introducing Amazon EMR: A Superior Alternative to Databricks for Financial Services Development Teams\n",
      "\n",
      "Dear valued customers,\n",
      "\n",
      "We hope this message finds you well. As your trusted partner in cloud computing, we are excited to introduce Amazon Elastic MapReduce (EMR) as a replacement for Databricks services. At [Your Company], we are always looking for ways to enhance our offerings and provide the best possible solutions for our customers.\n",
      "\n",
      "Why Amazon EMR?\n",
      "----------------\n",
      "\n",
      "EMR is a fully managed, scalable, and secure big data service that allows you to run Apache Hadoop, Apache Spark, and other big data frameworks in the cloud. Here are some reasons why we believe EMR is a superior alternative to Databricks:\n",
      "\n",
      "1. **Scalability and Flexibility**: EMR provides a highly scalable and flexible architecture that can handle mixed workloads ranging from ETL batch workloads to long-term Spark processing jobs. With EMR, you can process large datasets and scale your processing capacity as needed, ensuring that your applications can handle increased data volumes and processing requirements.\n",
      "2. **Security and Compliance**: EMR is built on top of Amazon Web Services (AWS), which provides a robust security and compliance framework. With EMR, you can leverage AWS security features such as encryption, access controls, and data encryption, ensuring that your data is secure and compliant with industry regulations.\n",
      "3. **Cost-Effectiveness**: EMR offers significant cost savings compared to Databricks. With EMR, you can save on infrastructure costs, reduce overhead costs, and take advantage of AWS pricing models that provide greater cost predictability and transparency.\n",
      "4. **Seamless integration with AWS**: EMR is tightly integrated with other AWS services, making it easy to leverage other AWS services such as AWS Glue, AWS Redshift, and AWS Lake Formation. This integration allows you to create a fully integrated big data ecosystem that is scalable, secure, and cost-effective.\n",
      "5. **Improved Performance**: EMR provides improved performance and faster data processing times compared to Databricks. With EMR, you can expect faster data processing times, reduced latency, and improved overall performance, which can lead to a better end-user experience.\n",
      "\n",
      "How to Get Started with Amazon EMR\n",
      "------------------------------------\n",
      "\n",
      "Migrating to Amazon EMR is easier than ever. Here are the steps you can follow to get started:\n",
      "\n",
      "1. **Contact Us**: Reach out to your [Your Company] representative or contact us directly to express your interest in migrating to Amazon EMR.\n",
      "2. **Assessment**: We will conduct a thorough assessment of your current Databricks infrastructure and workloads to identify the optimal migration strategy.\n",
      "3. **Migration**: We will work with you to migrate your Databricks infrastructure to Amazon EMR, ensuring a seamless transition with minimal downtime.\n",
      "4. **Optimization**: Once migrated, we will optimize your EMR cluster for performance, security, and cost-effectiveness.\n",
      "\n",
      "Conclusion\n",
      "----------\n",
      "\n",
      "In conclusion, we believe that Amazon EMR is a superior alternative to Databricks for financial services development teams. With its scalability, flexibility, security, and cost-effectiveness, EMR provides a robust big data platform that can handle mixed workloads and meet the evolving needs of your applications.\n",
      "\n",
      "We are excited to help you migrate to Amazon EMR and take advantage of its many benefits. If you have any questions or would like to learn more about EMR, please do not hesitate to reach out to us.\n",
      "\n",
      "Thank you for your time, and we look forward to working with you.\n",
      "\n",
      "Best regards,\n",
      "\n",
      "[Your Name]\n",
      "[Your Company]\n"
     ]
    }
   ],
   "source": [
    "# temp = 0.9\n",
    "prompt = \"\"\"\n",
    "Help me propose to our customers to replace Databricks services with Amazon EMR.\n",
    "Here are details about our customers:\n",
    "They are developer teams developing applications for financial services.\n",
    "Our customers use mixed workloads ranging from ETL batch workloads to long-term Spark processing jobs.\n",
    "Our customers often use Hive for SQL processing.\n",
    "\"\"\"\n",
    "response = llama(prompt, temperature=0.9)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sure, here's a proposal template you can use to suggest replacing Databricks services with Amazon EMR:\n",
      "\n",
      "Subject: Enhancing Your Data Processing Capabilities with Amazon EMR\n",
      "\n",
      "Dear [Customer Name],\n",
      "\n",
      "I hope this message finds you well. As a valued customer of [Your Company], we are committed to providing you with the best possible solutions for your data processing needs. As part of our ongoing efforts to improve your experience, we would like to introduce you to Amazon EMR, a highly scalable and cost-effective data processing service offered by Amazon Web Services (AWS).\n",
      "\n",
      "Background Information:\n",
      "\n",
      "You are currently using Databricks services for your data processing needs, which has served you well. However, we believe that Amazon EMR can offer several advantages that can help improve your processing capabilities and reduce costs. Amazon EMR is a fully managed service that makes it easy to process large amounts of data using popular open-source tools such as Spark, Hive, and Hadoop.\n",
      "\n",
      "Benefits of Amazon EMR:\n",
      "\n",
      "1. Scalability: Amazon EMR can quickly scale up or down to handle large or small workloads, ensuring that your data processing needs are always met.\n",
      "2. Cost-effective: Amazon EMR offers pay-as-you-go pricing, allowing you to only pay for the resources you use, reducing your overall costs.\n",
      "3. Security: Amazon EMR provides enterprise-grade security features, including encryption at rest and in transit, to protect your data.\n",
      "4. Integration: Amazon EMR can integrate seamlessly with other AWS services, such as Amazon S3, Amazon Redshift, and AWS Lambda, providing a complete data processing solution.\n",
      "5. Improved performance: Amazon EMR's distributed architecture can process large amounts of data faster than traditional Hadoop clusters, reducing your processing time.\n",
      "\n",
      "Proposal:\n",
      "\n",
      "We propose replacing Databricks services with Amazon EMR for your data processing needs. By leveraging Amazon EMR's scalability, cost-effectiveness, security, and performance, we can help you improve your data processing capabilities and reduce costs. We can help you migrate your existing data processing workflows to Amazon EMR and optimize them for better performance.\n",
      "\n",
      "Next Steps:\n",
      "\n",
      "We would like to schedule a call with your team to discuss the proposal in more detail and answer any questions you may have. Once you are ready, we can initiate the migration process and ensure a smooth transition to Amazon EMR.\n",
      "\n",
      "Thank you for considering our proposal. We look forward to the opportunity to work with you and help you improve your data processing capabilities.\n",
      "\n",
      "Best regards,\n",
      "\n",
      "[Your Name]\n",
      "[Your Company]\n",
      "[Your Contact Information]\n"
     ]
    }
   ],
   "source": [
    "# run the code again - the output should be different\n",
    "response = llama(prompt, temperature=0.9)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing the max tokens setting\n",
    "\n",
    "Determines the length of the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Subject: Enhancing Your Data Processing Capabilities with Amazon EMR\n",
      "\n",
      "D\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Help me propose to our customers to replace Databricks services with Amazon EMR.\n",
    "Here are details about our customers:\n",
    "They are developer teams developing applications for financial services.\n",
    "Our customers use mixed workloads ranging from ETL batch workloads to long-term Spark processing jobs.\n",
    "Our customers often use Hive for SQL processing.\n",
    "\"\"\"\n",
    "response = llama(prompt,max_tokens=20)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell reads in the text of the children's book The Velveteen Rabbit by Margery Williams, and stores it as a string named `text`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/TheVelveteenRabbit.txt\", \"r\", encoding='utf=8') as file:\n",
    "    text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Give me a summary of the following text in 50 words:\\n\\n\n",
    "{text}\n",
    "\"\"\"\n",
    "response = llama(prompt, model=\"togethercomputer/StripedHyena-Nous-7B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ### Response:\n",
      "The Velveteen Rabbit is a story about a toy rabbit who comes to life when a boy loves it for a long time. The rabbit meets other toys and learns about what it means to be real. He becomes friends with a wise skin horse and experiences many adventures. Eventually, the rabbit becomes very old and shabby, but the boy still loves him, and the rabbit realizes he is real. When the boy gets sick, the rabbit stays by his side, and when the boy recovers, they play together again in the garden.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# error because we have too many tokens.\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`inputs` tokens + `max_new_tokens` must be <= 4097\n",
    "\n",
    "For Llama 2 chat models, the sum of the input and max_new_tokens parameter must be <= 4097 tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4998"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sum of input tokens (prompt + Velveteen Rabbit text) and output tokens\n",
    "3974 + 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate tokens available for response after accounting for 3974 input tokens\n",
    "4097 - 3974"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set max_tokens to stay within limit on input + output tokens\n",
    "prompt = f\"\"\"\n",
    "Give me a summary of the following text in 50 words:\\n\\n\n",
    "{text}\n",
    "\"\"\"\n",
    "response = llama(prompt,\n",
    "                max_tokens=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  The Velveteen Rabbit is a heartwarming story about the relationship between a young boy and his stuffed toy rabbit. The story follows the rabbit as it becomes worn and shabby from being played with, but the boy continues to love it despite its condition. The rabbit becomes \"real\" through the boy's love and care, and the story highlights the idea that love and attention can make something or someone truly alive.\n",
      "\n",
      "The story is written in a simple and straightforward style, making it easy to follow and understand. The use of descriptive language\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': {'message': 'Input validation error: `inputs` tokens + `max_new_tokens` must be <= 4097. Given: 3974 `inputs` tokens and 124 `max_new_tokens`', 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': None}}\n"
     ]
    }
   ],
   "source": [
    "# increase max_tokens beyond limit on input + output tokens\n",
    "prompt = f\"\"\"\n",
    "Give me a summary of the following text in 50 words:\\n\\n\n",
    "{text}\n",
    "\"\"\"\n",
    "response = llama(prompt,\n",
    "                max_tokens=124)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asking a follow up question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:\n",
      "[INST]\n",
      "Help me write a birthday card for my dear friend Andrew.\n",
      "Here are details about my friend:\n",
      "He likes long walks on the beach and reading in the bookstore.\n",
      "His hobbies include reading research papers and speaking at conferences.\n",
      "His favorite color is light blue.\n",
      "He likes pandas.\n",
      "[/INST]\n",
      "\n",
      "model: togethercomputer/llama-2-7b-chat\n",
      "  Of course! Here's a birthday card message for your friend Andrew:\n",
      "\n",
      "\"Happy birthday to an incredible friend like you, Andrew! 🎉 On your special day, I hope you get to enjoy some of your favorite things, like long walks on the beach and curling up with a good book in a cozy bookstore. 📚🌊\n",
      "\n",
      "I'm so grateful for your love of learning and your passion for sharing your knowledge with others. Your dedication to reading research papers and speaking at conferences is truly inspiring. 💡🎤\n",
      "\n",
      "And let's not forget your love for pandas! 🐼 They're such adorable and fascinating creatures, just like you. 😊\n",
      "\n",
      "Here's to another amazing year of adventures, learning, and friendship! Cheers, Andrew! 🥳🎂\"\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Help me write a birthday card for my dear friend Andrew.\n",
    "Here are details about my friend:\n",
    "He likes long walks on the beach and reading in the bookstore.\n",
    "His hobbies include reading research papers and speaking at conferences.\n",
    "His favorite color is light blue.\n",
    "He likes pandas.\n",
    "\"\"\"\n",
    "response = llama(prompt, verbose=True)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Of course! Here's a revised version of the paragraph that includes the fact that the person also enjoys teaching:\n",
      "\n",
      "\"John is a highly skilled and experienced software engineer with a passion for programming. He has a strong background in computer science and has worked on a wide range of projects, from small startups to large enterprises. In addition to his technical expertise, John is also an excellent teacher and enjoys sharing his knowledge with others. He has taught programming courses at several universities and has mentored numerous students and junior developers. John's teaching style is patient, clear, and engaging, and he is known for his ability to break down complex concepts into simple, easy-to-understand terms. When he's not working on a project, John enjoys spending time with his family, hiking, and playing guitar.\"\n"
     ]
    }
   ],
   "source": [
    "prompt_2 = \"\"\"\n",
    "Oh, he also likes teaching. Can you rewrite it to include that?\n",
    "\"\"\"\n",
    "response_2 = llama(prompt_2)\n",
    "print(response_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
